{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "\n",
      "===================================BUG REPORT===================================\n",
      "Welcome to bitsandbytes. For bug reports, please submit your error trace to: https://github.com/TimDettmers/bitsandbytes/issues\n",
      "For effortless bug reporting copy-paste your error into this form: https://docs.google.com/forms/d/e/1FAIpQLScPB8emS3Thkp66nvqwmjTEgxp8Y9ufuWTzFyr9kJ5AoI47dQ/viewform?usp=sf_link\n",
      "================================================================================\n",
      "CUDA SETUP: CUDA runtime path found: /mnt/cs/voice/malykh-s/conda/miniconda3/envs/salmonn/lib/libcudart.so\n",
      "CUDA SETUP: Highest compute capability among GPUs detected: 6.1\n",
      "CUDA SETUP: Detected CUDA version 118\n",
      "CUDA SETUP: Loading binary /mnt/cs/voice/malykh-s/conda/miniconda3/envs/salmonn/lib/python3.9/site-packages/bitsandbytes/libbitsandbytes_cuda118_nocublaslt.so...\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import os\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES']='0,1,2'\n",
    "available_gpus = [torch.device(i) for i in range(torch.cuda.device_count())]\n",
    "print(len(available_gpus))\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "from model_multigpu import SALMONN\n",
    "from collections import Counter\n",
    "from pprint import pprint\n",
    "import time\n",
    "import librosa\n",
    "import soundfile as sf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_SEED = 42\n",
    "random.seed(RANDOM_SEED)\n",
    "np.random.seed(RANDOM_SEED)\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "device = available_gpus[0]\n",
    "delim = '# ' * 90\n",
    "\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "def count_parameters_all(model):\n",
    "    return sum(p.numel() for p in model.parameters())\n",
    "\n",
    "def get_llama_map(layers, zero_layers, n_gpus):\n",
    "    n_layers = len(layers)\n",
    "    n_layers_dist = n_layers - zero_layers\n",
    "    needed_count = n_layers_dist / (n_gpus - 1)\n",
    "    curr_gpu, curr_count = 1, 0\n",
    "    llama_map = dict()\n",
    "    for i in range(len(layers)):\n",
    "        layer = layers[i]\n",
    "        if i < zero_layers:\n",
    "            llama_map[layer] = 0\n",
    "            continue\n",
    "        if curr_count < needed_count:\n",
    "            llama_map[layer] = curr_gpu\n",
    "            curr_count += 1\n",
    "        else:\n",
    "            curr_count = 0\n",
    "            curr_gpu = min(n_gpus, curr_gpu + 1)\n",
    "            llama_map[layer] = curr_gpu\n",
    "            curr_count += 1\n",
    "    return llama_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt_path = '/mnt/cs/voice/malykh-s/PycharmProjects/SALMONN/SALMONN-7B/salmonn_7b_v0.pth'\n",
    "whisper_path = '/mnt/cs/voice/malykh-s/PycharmProjects/SALMONN/whisper-large-v2/'\n",
    "beats_path = '/mnt/cs/voice/malykh-s/PycharmProjects/SALMONN/BEATs/BEATs_iter3_plus_AS2M_finetuned_on_AS2M_cpt2.pt'\n",
    "vicuna_path = '/mnt/cs/voice/malykh-s/PycharmProjects/SALMONN/vicuna-7b-v1.5/'\n",
    "lora_alpha = 32\n",
    "low_resource = False\n",
    "llama_layers = ['model.embed_tokens'] + [f'model.layers.{i}' for i in range(0, 32)] + ['model.norm', 'lm_head']\n",
    "llama_map = get_llama_map(llama_layers, zero_layers=1, n_gpus=len(available_gpus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b1d07640aa14418a2d4a735378ec755",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "696681274\n",
      "7530008249\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SALMONN(\n",
       "  (speech_encoder): WhisperEncoder(\n",
       "    (conv1): Conv1d(80, 1280, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "    (conv2): Conv1d(1280, 1280, kernel_size=(3,), stride=(2,), padding=(1,))\n",
       "    (embed_positions): Embedding(1500, 1280)\n",
       "    (layers): ModuleList(\n",
       "      (0-31): 32 x WhisperEncoderLayer(\n",
       "        (self_attn): WhisperAttention(\n",
       "          (k_proj): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "          (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        )\n",
       "        (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (activation_fn): GELUActivation()\n",
       "        (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "        (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (ln_speech): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "  (beats): BEATs(\n",
       "    (post_extract_proj): Linear(in_features=512, out_features=768, bias=True)\n",
       "    (patch_embedding): Conv2d(1, 512, kernel_size=(16, 16), stride=(16, 16), bias=False)\n",
       "    (dropout_input): Dropout(p=0.0, inplace=False)\n",
       "    (encoder): TransformerEncoder(\n",
       "      (pos_conv): Sequential(\n",
       "        (0): Conv1d(768, 768, kernel_size=(128,), stride=(1,), padding=(64,), groups=16)\n",
       "        (1): SamePad()\n",
       "        (2): GELU(approximate='none')\n",
       "      )\n",
       "      (layers): ModuleList(\n",
       "        (0): TransformerSentenceEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (dropout_module): Dropout(p=0.0, inplace=False)\n",
       "            (relative_attention_bias): Embedding(320, 12)\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (grep_linear): Linear(in_features=64, out_features=8, bias=True)\n",
       "          )\n",
       "          (dropout1): Dropout(p=0.0, inplace=False)\n",
       "          (dropout2): Dropout(p=0.0, inplace=False)\n",
       "          (dropout3): Dropout(p=0.0, inplace=False)\n",
       "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (1-11): 11 x TransformerSentenceEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (dropout_module): Dropout(p=0.0, inplace=False)\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (grep_linear): Linear(in_features=64, out_features=8, bias=True)\n",
       "            (relative_attention_bias): Embedding(320, 12)\n",
       "          )\n",
       "          (dropout1): Dropout(p=0.0, inplace=False)\n",
       "          (dropout2): Dropout(p=0.0, inplace=False)\n",
       "          (dropout3): Dropout(p=0.0, inplace=False)\n",
       "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "    (predictor_dropout): Dropout(p=0.0, inplace=False)\n",
       "    (predictor): Linear(in_features=768, out_features=527, bias=True)\n",
       "  )\n",
       "  (ln_audio): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  (speech_Qformer): BertLMHeadModel(\n",
       "    (bert): BertModel(\n",
       "      (embeddings): BertEmbeddings(\n",
       "        (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "        (position_embeddings): Embedding(512, 768)\n",
       "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (encoder): BertEncoder(\n",
       "        (layer): ModuleList(\n",
       "          (0-1): 2 x BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (crossattention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=2048, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=2048, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (intermediate_query): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output_query): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (cls): BertOnlyMLMHead(\n",
       "      (predictions): BertLMPredictionHead(\n",
       "        (transform): BertPredictionHeadTransform(\n",
       "          (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (transform_act_fn): GELUActivation()\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (decoder): Linear(in_features=768, out_features=30522, bias=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (llama_model): PeftModelForCausalLM(\n",
       "    (base_model): LoraModel(\n",
       "      (model): LlamaForCausalLM(\n",
       "        (model): LlamaModel(\n",
       "          (embed_tokens): Embedding(32000, 4096, padding_idx=0)\n",
       "          (layers): ModuleList(\n",
       "            (0-31): 32 x LlamaDecoderLayer(\n",
       "              (self_attn): LlamaAttention(\n",
       "                (q_proj): Linear(\n",
       "                  in_features=4096, out_features=4096, bias=False\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Dropout(p=0.1, inplace=False)\n",
       "                  )\n",
       "                  (lora_A): ModuleDict(\n",
       "                    (default): Linear(in_features=4096, out_features=8, bias=False)\n",
       "                  )\n",
       "                  (lora_B): ModuleDict(\n",
       "                    (default): Linear(in_features=8, out_features=4096, bias=False)\n",
       "                  )\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                )\n",
       "                (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "                (v_proj): Linear(\n",
       "                  in_features=4096, out_features=4096, bias=False\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Dropout(p=0.1, inplace=False)\n",
       "                  )\n",
       "                  (lora_A): ModuleDict(\n",
       "                    (default): Linear(in_features=4096, out_features=8, bias=False)\n",
       "                  )\n",
       "                  (lora_B): ModuleDict(\n",
       "                    (default): Linear(in_features=8, out_features=4096, bias=False)\n",
       "                  )\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                )\n",
       "                (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "                (rotary_emb): LlamaRotaryEmbedding()\n",
       "              )\n",
       "              (mlp): LlamaMLP(\n",
       "                (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "                (down_proj): Linear(in_features=11008, out_features=4096, bias=False)\n",
       "                (up_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "                (act_fn): SiLUActivation()\n",
       "              )\n",
       "              (input_layernorm): LlamaRMSNorm()\n",
       "              (post_attention_layernorm): LlamaRMSNorm()\n",
       "            )\n",
       "          )\n",
       "          (norm): LlamaRMSNorm()\n",
       "        )\n",
       "        (lm_head): Linear(in_features=4096, out_features=32000, bias=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (speech_llama_proj): Linear(in_features=768, out_features=4096, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = SALMONN(\n",
    "    ckpt=ckpt_path,\n",
    "    whisper_path=whisper_path,\n",
    "    beats_path=beats_path,\n",
    "    vicuna_path=vicuna_path,\n",
    "    lora_alpha=lora_alpha,\n",
    "    low_resource=low_resource,\n",
    "    encoder_device=available_gpus[0],\n",
    "    llama_device_map=llama_map,\n",
    "    llama_dtype=torch.bfloat16\n",
    ")\n",
    "print(count_parameters(model))\n",
    "print(count_parameters_all(model))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPEECH_ENCODER\n",
      "Trainable parameter count:  636_784_640\n",
      "All parameter count:  636_784_640\n",
      "[(torch.float32, 487)]\n",
      "Size: 2429.14MiB\n",
      "# # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # \n",
      "LN_SPEECH\n",
      "Trainable parameter count:  2_560\n",
      "All parameter count:  2_560\n",
      "[(torch.float32, 2)]\n",
      "Size: 0.01MiB\n",
      "# # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # \n",
      "BEATS\n",
      "Trainable parameter count:  0\n",
      "All parameter count:  90_717_055\n",
      "[(torch.float32, 241)]\n",
      "Size: 346.06MiB\n",
      "# # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # \n",
      "LN_AUDIO\n",
      "Trainable parameter count:  1_536\n",
      "All parameter count:  1_536\n",
      "[(torch.float32, 2)]\n",
      "Size: 0.01MiB\n",
      "# # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # \n",
      "SPEECH_QFORMER\n",
      "Trainable parameter count:  56_741_946\n",
      "All parameter count:  56_741_946\n",
      "[(torch.float32, 73)]\n",
      "Size: 216.45MiB\n",
      "# # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # \n",
      "LLAMA_MODEL\n",
      "Trainable parameter count:  0\n",
      "All parameter count:  6_742_609_920\n",
      "[(torch.bfloat16, 291), (torch.float32, 128)]\n",
      "Size: 12868.51MiB\n",
      "# # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # \n",
      "SPEECH_LLAMA_PROJ\n",
      "Trainable parameter count:  3_149_824\n",
      "All parameter count:  3_149_824\n",
      "[(torch.float32, 2)]\n",
      "Size: 12.02MiB\n",
      "# # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # \n",
      "Size: 15872.19MiB\n"
     ]
    }
   ],
   "source": [
    "total_bits = 0\n",
    "for key in model._modules:\n",
    "    print(key.upper())\n",
    "    print('Trainable parameter count: ', f'{count_parameters(model._modules[key]):_}')\n",
    "    print('All parameter count: ', f'{count_parameters_all(model._modules[key]):_}')\n",
    "    dtypes = []\n",
    "    bits = 0\n",
    "    for elem in model._modules[key].parameters():\n",
    "        dtypes.append(elem.dtype)\n",
    "        bits_sub = 1\n",
    "        for part in elem.shape:\n",
    "            bits_sub *= part\n",
    "        if elem.dtype == torch.int8:\n",
    "            bits += bits_sub * 8\n",
    "        elif elem.dtype == torch.float16:\n",
    "            bits += bits_sub * 16\n",
    "        elif elem.dtype == torch.bfloat16:\n",
    "            bits += bits_sub * 16\n",
    "        elif elem.dtype == torch.float32:\n",
    "            bits += bits_sub * 32\n",
    "        else:\n",
    "            print('bad')\n",
    "    print(Counter(dtypes).most_common())\n",
    "    print(f'Size: {bits/(2**23):.2f}MiB')\n",
    "    print(delim)\n",
    "    total_bits += bits\n",
    "print(f'Size: {total_bits/(2**23):.2f}MiB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model.embed_tokens': 0,\n",
       " 'model.layers.0': 1,\n",
       " 'model.layers.1': 1,\n",
       " 'model.layers.2': 1,\n",
       " 'model.layers.3': 1,\n",
       " 'model.layers.4': 1,\n",
       " 'model.layers.5': 1,\n",
       " 'model.layers.6': 1,\n",
       " 'model.layers.7': 1,\n",
       " 'model.layers.8': 1,\n",
       " 'model.layers.9': 1,\n",
       " 'model.layers.10': 1,\n",
       " 'model.layers.11': 1,\n",
       " 'model.layers.12': 1,\n",
       " 'model.layers.13': 1,\n",
       " 'model.layers.14': 1,\n",
       " 'model.layers.15': 1,\n",
       " 'model.layers.16': 1,\n",
       " 'model.layers.17': 2,\n",
       " 'model.layers.18': 2,\n",
       " 'model.layers.19': 2,\n",
       " 'model.layers.20': 2,\n",
       " 'model.layers.21': 2,\n",
       " 'model.layers.22': 2,\n",
       " 'model.layers.23': 2,\n",
       " 'model.layers.24': 2,\n",
       " 'model.layers.25': 2,\n",
       " 'model.layers.26': 2,\n",
       " 'model.layers.27': 2,\n",
       " 'model.layers.28': 2,\n",
       " 'model.layers.29': 2,\n",
       " 'model.layers.30': 2,\n",
       " 'model.layers.31': 2,\n",
       " 'model.norm': 2,\n",
       " 'lm_head': 2}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.llama_model.hf_device_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "wav_paths = ['/mnt/cs/voice/malykh-s/PycharmProjects/SALMONN/SALMONN-7B/wav_examples/tada.wav', \n",
    "             '/mnt/cs/voice/malykh-s/PycharmProjects/SALMONN/SALMONN-7B/wav_examples/cartoon_monkey.wav',\n",
    "             '/mnt/cs/voice/malykh-s/PycharmProjects/SALMONN/SALMONN-7B/wav_examples/machine_gun.wav']\n",
    "prompts = ['Describe the following sound in great detail', \n",
    "           'What animal is laughing like this? Provide datailed reasoning for you answer', \n",
    "           'What gun is this? Tell me about its characteristics']\n",
    "wavs = []\n",
    "for wav_path in wav_paths:\n",
    "    wav, sr = sf.read(wav_path)\n",
    "    if len(wav.shape) == 2:\n",
    "        wav = wav[:, 0]\n",
    "    if len(wav) > 30 * sr:\n",
    "        wav = wav[: 30 * sr]\n",
    "    if sr != 16000:\n",
    "        wav = librosa.resample(wav, orig_sr=sr, target_sr=16000, res_type=\"fft\")\n",
    "    wavs.append(wav)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('The sound is a brass fanfare. The fanfare is played by a brass ensemble '\n",
      " 'consisting of trumpets, trombones, and French horns. The sound is loud and '\n",
      " 'brassy. The fanfare is played to announce the arrival of an important '\n",
      " 'person, such as a king or queen, or to celebrate a victory. The fanfare can '\n",
      " 'also be used to signal the start of a parade or a military march. The sound '\n",
      " 'is energetic and uplifting. The fanfare can also be used to create a sense '\n",
      " 'of excitement and anticipation. The sound can also be used to create a sense '\n",
      " 'of triumph and victory. The sound can also be used to create a sense of '\n",
      " 'grandeur and')\n",
      "46.22 seconds\n",
      "# # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # \n",
      "('The animal that is laughing like this is a hyena. The hyena is known for its '\n",
      " 'high-pitched laughter, which it uses to communicate with other hyenas and to '\n",
      " 'attract the attention of potential mates. The hyena is a social animal that '\n",
      " 'lives in large groups called clans, and it is one of the most intelligent '\n",
      " 'and adaptable animals in the animal kingdom. In addition to its distinctive '\n",
      " 'laughter, the hyena is also known for its sharp teeth and powerful jaws, '\n",
      " 'which it uses to hunt and defend its territory.')\n",
      "37.86 seconds\n",
      "# # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # \n",
      "('The gun being used is a M249 SAW (Squad Automatic Weapon). It is a '\n",
      " 'lightweight machine gun that fires 7.62x51mm NATO rounds from a belt of '\n",
      " 'linked ammunition. The SAW is known for its high rate of fire and is '\n",
      " 'typically used by infantry squads in support of riflemen. The sound of the '\n",
      " 'M249 SAW is characterized by its distinctive \"ping-ping-ping\" sound as the '\n",
      " 'rounds are fired from the belt.')\n",
      "35.58 seconds\n",
      "# # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # \n",
      "119.66 total seconds\n"
     ]
    }
   ],
   "source": [
    "total_time = 0\n",
    "for i in range(len(wavs)):\n",
    "    wav, prompt = wavs[i], prompts[i]\n",
    "    t0 = time.time()\n",
    "    with torch.no_grad():\n",
    "        generation = model.generate(wav, prompt=prompt)\n",
    "    t1 = time.time()\n",
    "    total = t1-t0\n",
    "    total_time += total\n",
    "    pprint(generation[0])\n",
    "    print(f'{total:.2f} seconds')\n",
    "    print(delim)\n",
    "print(f'{total_time:.2f} total seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('The sound is a trumpet fanfare. The trumpet is a brass instrument that '\n",
      " 'produces sound by blowing air into a mouthpiece that is attached to a metal '\n",
      " 'tube. The trumpet fanfare is a piece of music that is played by the trumpet. '\n",
      " 'The trumpet fanfare is a piece of music that is played by the trumpet. The '\n",
      " 'trumpet fanfare is a piece of music that is played by the trumpet. The '\n",
      " 'trumpet fanfare is a piece of music that is played by the trumpet. The '\n",
      " 'trumpet fanfare is a piece of music that is played by the trumpet. The '\n",
      " 'trumpet fanfare is a piece')\n",
      "44.91 seconds\n",
      "# # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # \n",
      "('The animal that is laughing like this is a hyena. Hyenas are known for their '\n",
      " 'high-pitched laughter, which they use to communicate with each other and to '\n",
      " 'attract the attention of other animals. They are also known for their social '\n",
      " 'behavior, living in large groups and cooperating to hunt and protect their '\n",
      " 'territory. In addition to their distinctive laughter, hyenas are also known '\n",
      " 'for their distinctive physical features, such as their long necks and '\n",
      " 'powerful jaws.')\n",
      "31.08 seconds\n",
      "# # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # \n",
      "('This is a shotgun. It is a firearm that is designed to shoot a single '\n",
      " 'projectile called a shot, which is typically made up of multiple smaller '\n",
      " 'pellets. Shotguns are typically used for hunting and sport shooting, and are '\n",
      " 'known for their ability to fire a wide spread of pellets, making them '\n",
      " 'effective at hitting multiple targets at once. This particular shotgun '\n",
      " 'appears to be a semi-automatic, meaning it can fire multiple shots with a '\n",
      " 'single pull of the trigger. It also appears to have a pistol grip, which '\n",
      " 'allows the user to hold the gun with a more comfortable and stable grip.')\n",
      "40.04 seconds\n",
      "# # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # \n",
      "116.03 total seconds\n"
     ]
    }
   ],
   "source": [
    "total_time = 0\n",
    "for i in range(len(wavs)):\n",
    "    wav, prompt = wavs[i], prompts[i]\n",
    "    t0 = time.time()\n",
    "    with torch.no_grad():\n",
    "        generation = model.generate(wav, prompt=prompt)\n",
    "    t1 = time.time()\n",
    "    total = t1-t0\n",
    "    total_time += total\n",
    "    pprint(generation[0])\n",
    "    print(f'{total:.2f} seconds')\n",
    "    print(delim)\n",
    "print(f'{total_time:.2f} total seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('The sound is a trumpet fanfare. The trumpet is a brass instrument that '\n",
      " 'produces sound by blowing air through a mouthpiece. The fanfare is a musical '\n",
      " 'piece that is typically used to announce the arrival of an important person, '\n",
      " 'such as a king or queen. The trumpet fanfare is often used in military '\n",
      " 'ceremonies to announce the arrival of a high-ranking officer. The sound of '\n",
      " 'the trumpet fanfare is loud and brassy, with a clear and crisp tone. The '\n",
      " 'trumpet fanfare is typically played by a single trumpet, but it can also be '\n",
      " 'played by a group of trumpets. The sound of the trumpet fan')\n",
      "44.99 seconds\n",
      "# # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # \n",
      "('The animal that is laughing like this is a hyena. The hyena is known for its '\n",
      " 'high-pitched laughter and is often referred to as the \"laughing hyena.\" The '\n",
      " 'hyena is a social animal that lives in groups called clans and is found in '\n",
      " 'grasslands and savannas in Africa. It is a scavenger and feeds on the '\n",
      " 'carcasses of other animals, as well as insects and small mammals. The hyena '\n",
      " 'is also known for its distinctive vocalizations, including its high-pitched '\n",
      " 'laughter, which it uses to communicate with other members of its clan.')\n",
      "41.38 seconds\n",
      "# # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # \n",
      "('This is a machine gun. It is an automatic firearm that is designed to fire '\n",
      " 'multiple rounds of ammunition with a single pull of the trigger. Machine '\n",
      " 'guns are often used by military and law enforcement personnel, as well as by '\n",
      " 'civilians for sporting and recreational purposes. They are known for their '\n",
      " 'high rate of fire and ability to quickly empty a magazine.')\n",
      "27.60 seconds\n",
      "# # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # \n",
      "113.96 total seconds\n"
     ]
    }
   ],
   "source": [
    "total_time = 0\n",
    "for i in range(len(wavs)):\n",
    "    wav, prompt = wavs[i], prompts[i]\n",
    "    t0 = time.time()\n",
    "    with torch.no_grad():\n",
    "        generation = model.generate(wav, prompt=prompt)\n",
    "    t1 = time.time()\n",
    "    total = t1-t0\n",
    "    total_time += total\n",
    "    pprint(generation[0])\n",
    "    print(f'{total:.2f} seconds')\n",
    "    print(delim)\n",
    "print(f'{total_time:.2f} total seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "73.00 seconds\n",
      "('The sound is of a brass instrument playing a loud and triumphant fanfare. '\n",
      " 'The instrument is likely a bugle or trumpet, and the sound is brassy and '\n",
      " 'bright. The player is likely a military musician or a brass band member. The '\n",
      " 'sound is likely being played in a military setting, such as a military '\n",
      " 'parade or a victory celebration. The sound is brassy and bright, and the '\n",
      " 'player is likely a military musician or a brass band member. The sound is '\n",
      " 'likely being played in a military setting, such as a military parade or a '\n",
      " 'victory celebration. The sound is brassy and bright, and the player is '\n",
      " 'likely a military musician or a brass band member')\n",
      "# # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # \n",
      "('The animal that is laughing like this is a hyena. Hyenas are known for their '\n",
      " 'distinctive, high-pitched laughter, which they use to communicate and bond '\n",
      " 'with one another. They also use this laughter to attract the attention of '\n",
      " 'other hyenas and to intimidate their prey. Hyenas are social animals that '\n",
      " 'live in groups called clans, and they play an important role in the '\n",
      " 'ecosystem as scavengers and predators. They can be found in a variety of '\n",
      " 'habitats, including grasslands, savannas, and deserts, and they are native '\n",
      " 'to Africa, Asia, and Europe.')\n",
      "# # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # \n",
      "('This is a machine gun. It is a type of firearm that is designed to fire '\n",
      " 'multiple rounds of ammunition with a single pull of the trigger. Machine '\n",
      " 'guns are often used by military and law enforcement personnel, as well as by '\n",
      " 'civilians for recreational purposes. They are known for their high rate of '\n",
      " 'fire and the ability to quickly spray a large volume of bullets in a short '\n",
      " 'period of time. The specific characteristics of a machine gun can vary '\n",
      " 'depending on its design and the type of ammunition it is firing. For '\n",
      " 'example, some machine guns use belt-fed ammunition, while others use '\n",
      " 'drum-fed ammunition. Additionally, some machine guns are designed to be '\n",
      " 'handh')\n",
      "# # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # \n"
     ]
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "with torch.no_grad():\n",
    "    output = model.generate(wavs, prompts)\n",
    "t1 = time.time()\n",
    "total = t1-t0\n",
    "print(f'{total:.2f} seconds')\n",
    "for answer in output:\n",
    "    pprint(answer)\n",
    "    print(delim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72.38 seconds\n",
      "('The sound is a brass fanfare. The brass section is playing in unison, with '\n",
      " 'the trumpets and trombones playing in harmony. The sound is loud and '\n",
      " 'boisterous, with a sense of triumph and celebration. The brass section is '\n",
      " 'playing with a lot of energy and enthusiasm. The sound is loud and '\n",
      " 'boisterous, with a sense of triumph and celebration. The brass section is '\n",
      " 'playing with a lot of energy and enthusiasm. The sound is loud and '\n",
      " 'boisterous, with a sense of triumph and celebration. The brass section is '\n",
      " 'playing with a lot of energy and enthusiasm. The sound is loud and '\n",
      " 'boisterous, with a sense of triumph')\n",
      "# # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # \n",
      "('The animal that is laughing like this is a hyena. The hyena is known for its '\n",
      " 'distinctive laughing call, which is often described as sounding like a human '\n",
      " 'laughing. The hyena is a social animal that lives in groups and is found in '\n",
      " 'grasslands and savannas in Africa. It is a scavenger and feeds on the '\n",
      " 'carcasses of other animals, as well as on insects, fruits, and vegetables. '\n",
      " 'The hyena is also known for its intelligence and problem-solving abilities, '\n",
      " 'and has been observed exhibiting a range of complex behaviors, including '\n",
      " 'cooperation, communication, and even play.')\n",
      "# # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # \n",
      "('The gun being used is a Glock 17. It is a semi-automatic pistol that is '\n",
      " 'widely used by law enforcement agencies and military forces around the '\n",
      " 'world. The Glock 17 is known for its reliability, durability, and ease of '\n",
      " 'use. It has a 17-round magazine capacity and is chambered in 9x19mm '\n",
      " 'Parabellum ammunition. The gun is also lightweight and easy to handle, '\n",
      " 'making it a popular choice among law enforcement officers and civilians '\n",
      " 'alike.')\n",
      "# # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # \n"
     ]
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "with torch.no_grad():\n",
    "    output = model.generate(wavs, prompts)\n",
    "t1 = time.time()\n",
    "total = t1-t0\n",
    "print(f'{total:.2f} seconds')\n",
    "for answer in output:\n",
    "    pprint(answer)\n",
    "    print(delim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72.49 seconds\n",
      "('The sound is a trumpet fanfare. The trumpet is a brass instrument that '\n",
      " 'produces sound by blowing air through a mouthpiece into a long tube. The '\n",
      " 'trumpet fanfare is a musical piece that is typically used to announce the '\n",
      " 'arrival of an important person, such as a king or queen. The trumpet fanfare '\n",
      " 'is often used in military ceremonies to announce the arrival of a general or '\n",
      " 'other high-ranking officer. The trumpet fanfare is also used in sports '\n",
      " 'events, such as football games, to announce the arrival of the home team. '\n",
      " 'The trumpet fanfare is typically played by a single trumpet player, but it '\n",
      " 'can also be played')\n",
      "# # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # \n",
      "('The animal that is laughing like this is a hyena. Hyenas are known for their '\n",
      " 'distinctive, high-pitched laughter, which they use to communicate with each '\n",
      " 'other and to attract the attention of other animals. They are also known for '\n",
      " 'their social and cooperative behavior, and often live in groups or \"clans\" '\n",
      " 'that work together to hunt and protect their territory. While hyenas are '\n",
      " 'native to Africa, they have been introduced to other parts of the world and '\n",
      " 'can now be found in zoos and wildlife sanctuaries around the globe.')\n",
      "# # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # \n",
      "('This is a .50 caliber sniper rifle. It is a high-powered rifle that fires a '\n",
      " 'large caliber bullet at a high velocity. It is often used by military and '\n",
      " 'law enforcement agencies for long-range precision shooting. The rifle has a '\n",
      " 'long barrel, which helps to increase its range and accuracy. It also has a '\n",
      " 'scope, which allows the shooter to accurately aim the bullet at a target '\n",
      " 'from a distance. The rifle is known for its powerful recoil, which can be '\n",
      " 'difficult to control, especially for inexperienced shooters.')\n",
      "# # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # \n"
     ]
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "with torch.no_grad():\n",
    "    output = model.generate(wavs, prompts)\n",
    "t1 = time.time()\n",
    "total = t1-t0\n",
    "print(f'{total:.2f} seconds')\n",
    "for answer in output:\n",
    "    pprint(answer)\n",
    "    print(delim)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "salmonn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
